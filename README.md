코딩 관련 질문에 대해
캐릭터 1과 캐릭터 2가 서로 반대 의견으로 토론하고,
선택지를 통해 사용자 참여가 이어지는 인터랙티브 토론 게임

+사용자가 한글로 문제를 입력
캐릭터 1과 캐릭터 2가 각기 다른 해결 아이디어 제시 / 해결 아이디어에 맞는 코드도 함께 제공

질문은 한 번이 아니라 흐름을 따라 계속 이어져야 하고, 선택에 따라 분기가 생김

exaone 모델 사용

🔁 구조 요약
사용자 질문 (혹은 시스템 제공)
예: "for문과 while문, 어느 게 더 좋아?"

캐릭터 1과 캐릭터 2가 반대 의견
캐릭터 1: "for문은 반복 횟수가 명확할 때 효율적이다"
캐릭터 2: "while문이 더 유연하다. 조건만 있으면 무한히 쓸 수 있다"

선택지 등장

1번 의견에 들어봄

2번 의견 들어봄

둘이 계속 토론하게 하기

추가 질문 하기

새로운 질문으로 넘어가기

사용자 선택 → 다음 시나리오로 이어짐
선택한 흐름에 따라 다음 토론이 생김 → 점점 깊어짐

설치 및 실행 방법
1. Ollama 설치 및 모델 다운로드
이 애플리케이션은 로컬에 설치된 Ollama 서버에 의존합니다. 먼저 Ollama 공식 웹사이트에서 Ollama를 설치하세요.

설치 후, 터미널에서 원하는 언어 모델을 다운로드합니다. exaone 모델이 기본값으로 설정되어 있지만, 다른 모델을 사용할 수도 있습니다.

ollama pull exaone

2. 프로젝트 실행
A. 필요한 라이브러리 설치

gradio와 requests 라이브러리가 필요합니다.

pip install gradio requests

B. 애플리케이션 실행

제공된 파이썬 코드를 app.py와 같은 파일로 저장한 후, 터미널에서 실행합니다.

python app.py

명령어를 실행하면 로컬 Gradio 서버가 시작되며, 터미널에 표시되는 URL을 통해 웹 브라우저에서 앱에 접속할 수 있습니다.

사용 방법
Ollama 연결 확인: 애플리케이션 실행 후, Ollama URL이 http://localhost:11434로 올바르게 설정되었는지 확인하세요. Model 드롭다운에서 사용 가능한 모델 목록이 자동으로 로드됩니다.

설정 조정: 왼쪽 패널에서 'Greedy Rebel'과 'DP Master'의 이름, 시스템 프롬프트, 메모리 크기 등을 자유롭게 변경할 수 있습니다.

토론 시작: 📝 토론 주제 입력창에 토론하고 싶은 주제를 입력한 후 Start 버튼을 누르세요.

토론 진행: 두 에이전트가 차례로 답변을 생성하며 토론을 진행합니다. 답변이 완료되면 아래쪽에 나타나는 버튼을 통해 다음 대화의 방향을 결정할 수 있습니다.

토론 제어: Stop 버튼으로 언제든지 토론을 중단할 수 있고, Reset 버튼으로 모든 대화 기록을 초기화할 수 있습니다.
